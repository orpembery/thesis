In this \lcnamecref{app:complexerror}, we recall the definition of some elementary properties of \emph{complex-valued} random variables, properties that are slightly different to their analogues for real-valued random variables. We then prove that the standard unbiased estimator of the variance (with Bessel's correction) of a complex-valued random variable  is indeed an unbiased estimator of the variance.
\optodo{Find refs for everything here, and say the proof is standard, similar to the real case - find a ref.}
\ednote{Euan, I'll find references for everything in here (and say the proof of \cref{lem:unbiased} is similar to the real case)}
\bde[Complex-valued random variable]
If $\OFP$ is a probability space, then a \defn{complex-valued} random variable is a measurable map $Y:\Omega\rightarrow \CC,$ where $\CC$ is equipped with the Borel $\sigma$-algebra.
\ede

\bde[Mean and variance of a complex-valued random variable]
Let $Y$ be a complex-valued random variable. The \defn{expectation of $Y$} is
\beqs
\EXP{Y} \de \EXP{\Re{Y}} + i \EXP{\Im{Y}},
\eeqs
if it exists. The \defn{variance of $Y$} is
\beqs
\VAR{Y} \de \EXP{\abs{Y}^2} - \abs{\EXP{Y}}^2
\eeqs
if it exists.
\ede

\bde[$\sigma$-algebra generated by a random variable]
Let $Y$ be a complex-valued random variable. The \defn{$\sigma$-algebra generated by $Y$} is
\beqs
\sigalggen{Y} \de \set{Y^{-1}\mleft(E\mright) \st E \in \sigma\mleft(\RR\mright)},
\eeqs
where $Y^{-1}$ denotes the pullback.
\ede

\bde[Independent $\sigma$-algebras]
Two $\sigma$-algebras $\cFo$ and $\cFt$ on $\Omega$ are \defn{independent} if all their sets are independent, i.e.
\beqs
\PP\mleft(\Eo\mright) \cap \PP\mleft(\Et\mright) = \PP\mleft(\Eo\mright)\PP\mleft(\Et\mright)
\eeqs
for all $\Eo \in \cFo$ and $\Et \in \cFt.$
\ede

\bde[Independent random variables]
Two complex-valued random variables $\Yo$ and $\Yt$ are \defn{independent} if their respective generated $\sigma$-algebras are independent.
\ede

\ble[Independent implies uncorrelated]
If $\Yo$ and $\Yt$ are independent complex-valued random variables, then
\beqs
\EXP{\Yo\Ytbar} = \EXP{\Yo}\EXP{\Ytbar}.
\eeqs
\ele

\bde[Monte-Carlo estimator for $\EXP{Y}.$]
Let $Y$ be a complex-valued random variable, and $\Yo,\ldots,\YN$ be independent and identically distributed to $Y$. The \defn{Monte-Carlo estimator of $\EXP{Y}$} is
\beqs
\Yhat \de\frac1N \sum_{l=1}^N \Yl.
\eeqs
\ede

\bde[Unbiased estimator of the variance of the Monte-Carlo estimator]
Let $Y$ be a complex-valued random variable, and $\Yhat$ the Monte-Carlo estimator of $\EXP{Y}$. The estimator $\unbiased{\Yhat}{N}$ of $\VAR{\Yhat}$ is
\beq\label{eq:unbiased}
\unbiased{\Yhat}{N} \de \frac1{N(N-1)} \sum_{j=1}^N \abs{\Yj - \Yhat}^2.
\eeq
\ede

The factor $1/(N-1)$ in \cref{eq:unbiased} is known as \defn{Bessel's correction}\optodo{Ref}, and ensures the estimator is unbiased, as we now prove.

\ble[The unbiased estimator is unbiased]\label{lem:unbiased}
Let $Y$ be a complex-valued random variable and  $\Yhat$ the Monte-Carlo estimator of $\EXP{Y}$. Then $\unbiased{\Yhat}{N}$ is unbiased, i.e.,
\beqs
\EXP{\unbiased{\Yhat}{N}} = \VAR{\Yhat}.
\eeqs
\ele
\optodo{Consider coming back to the proof and rewriting it, as it's currently directly from Wikipedia.}
\bpf[Proof of \cref{lem:unbiased}]
We introduce the notation
\beqs
\mu \de \abs{\EXP{Y}}\quad\tand\quad\sigma \de \VAR{Y}
\eeqs
and we observe that
\beq\label{eq:varrelation}
\EXP{\abs{Y}^2} = \sigma^2 + \mu^2.
\eeq

Firstly, note that
\beqs
\VAR{\Yhat} = \VAR{\frac1N \sum_{l=1}^N \Yl} = \frac1{N^2} \VAR{\sum_{l=1}^N \Yl} = \frac1N \VAR{Y}.
\eeqs
Therefore, it is sufficient to show that $\unbiased{\Yhat}{N}$ is an unbiased estimator for $\VAR{Y}/N,$ or equivalently, $N\unbiased{\Yhat}{N}$ is an unbiased estimator for $\VAR{Y}.$ We show the latter by direct computation:
\begin{align*}
  \EXP{N\unbiased{\Yhat}{N}} &= \frac1{N-1} \EXP{\sum_{j=1}^N \abs{\Yj - \Yhat}^2}\\
  &= \frac1{N-1}\EXP{\sum_{j=1}^N \abs{\Yj  - \frac1{N} \sum_{l=1}^N \Yl}^2}\\
  & = \frac1{N-1} \EXP{\sum_{j=1}^N\mleft(\abs{\Yj}^2 - \frac1N \sum_{l=1}^N \mleft(\Yj \Ylbar + \Yl\Yjbar\mright) + \frac1{N^2} \abs{\sum_{l=1}^N  \Yl}^2\mright)}\\
  & = \frac1{N-1} \sum_{j=1}^N\mleft(\EXP{\abs{\Yj}^2} -\frac2N \EXP{\abs{\Yj}^2} -\frac1N \sum_{l\neq j} \EXP{\mleft(\Yj \Ylbar + \Yl\Yjbar\mright)} + \frac1{N^2}\EXP{ \abs{\sum_{l=1}^N  \Yl}^2}\mright)\\
  & = \frac1{N-1} \sum_{j=1}^N\mleft(\frac{N-2}N\EXP{\abs{\Yj}^2}-\frac1N \sum_{l\neq j} \EXP{\mleft(\Yj \Ylbar + \Yl\Yjbar\mright)} + \frac1{N^2}\EXP{ \mleft(\sum_{l=1}^N\Yl\mright)\mleft(\overline{\sum_{m=1}^N  \Ym}\mright)}\mright)\\
  & = \frac1{N-1} \sum_{j=1}^N\mleft(\frac{N-2}N\EXP{\abs{\Yj}^2}-\frac1N \sum_{l\neq j} \EXP{\mleft(\Yj \Ylbar + \Yl\Yjbar\mright)} + \frac1{N^2}\EXP{ \sum_{l=1}^N\mleft(\Yl\sum_{m=1}^N  \Ymbar\mright)}\mright)\\
  & = \frac1{N-1} \sum_{j=1}^N\mleft(\frac{N-2}N\EXP{\abs{\Yj}^2}-\frac1N \sum_{l\neq j} \EXP{\mleft(\Yj \Ylbar + \Yl\Yjbar\mright)} + \frac1{N^2}\EXP{ \sum_{l=1}^N\abs{\Yl}^2 + \sum_{l=1}^N \sum_{m\neq l} \Yl \Ymbar}\mright)\\
  & = \frac1{N-1} \sum_{j=1}^N\mleft(\frac{N-2}N\EXP{\abs{\Yj}^2}-\frac1N \sum_{l\neq j} \EXP{\mleft(\Yj \Ylbar + \Yl\Yjbar\mright)} + \frac1{N^2}\EXP{ \sum_{l=1}^N\abs{\Yl}^2} +\frac1{N^2} \sum_{l=1}^N \sum_{m\neq l} \EXP{\Yl \Ymbar}\mright)\\
  &= \frac1{N-1} \sum_{j=1}^N \mleft(\frac{N-2}N \mleft(\mu^2 + \sigma^2\mright) - \frac2N \mleft(N-1\mright) \mu^2 + \frac1{N^2} N \mleft(\mu^2 + \sigma^2\mright) + \frac1{N^2} N \mleft(N-1\mright) \mu^2\mright),\text{ by \cref{eq:varrelation}}\\
  &= \frac1{N-1} \sum_{j=1}^N \mleft( \frac{N-1}N \mleft(\mu^2 + \sigma^2\mright) - \frac{N-1}{N} \mu^2\mright)\\
  &= \frac1{N-1} \sum_{j=1}^N \frac{N-1}N \sigma^2\\
  &= \sigma^2.
  \end{align*}
\epf
