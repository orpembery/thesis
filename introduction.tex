\section{The subjects of the thesis}

The subjects of this thesis are rigorous theory and fast methods for the stochastic Helmholtz equation
\beq\label{eq:introhh}
\grad \cdot \mleft(A\grad u\mright) + k^2 \, n \, u = -f,
\eeq
where $A,$ $n,$ and $f$ are random fields (i.e., they are spatially heterogeneous and random). We are particularly interested in theory and methods that are applicable for large values of the wavenumber $k$, as the case of large $k$ is of interest in applications, and theoretically and computationally demanding.

\subsection{Motivation from Applications for the High-Frequency Stochastic Helmholtz Equation}

The Helmholtz equation is the simplest possible model of wave propagation. Indeed, if one seeks time-harmonic solutions of the scalar wave equation
\beq\label{eq:introwave}
n \, \frac{\partial^2 U}{\partial t^2} - \grad \cdot\mleft(A\grad U\mright) = F,
\eeq
that is, solutions of the form $U(t,\bx) = e^{ikt}u(\bx)$, then the spatial part $u$ satisfies \eqref{eq:introhh}; equivalently, \eqref{eq:introhh} is the Fourier transform in time  of \eqref{eq:introwave}. In certain scenarios, the time-harmonic Maxwell's equations reduce to \eqref{eq:introhh}, see, e.g., \cite[Remark 2.1]{MoSp:19} for this derivation.

The physical motivation for studying \eqref{eq:introhh} is, therefore, any physical scenario in which wave propagation can be modelled by either \eqref{eq:introwave} or Maxwell's equations. One prominent example of the usage of \eqref{eq:introwave} is in subsurface imaging, where the rock structures of the earth's crust are imaged by generating waves at the earth's surface, and recording the reflections of these waves from the rock structures. The waves within the earth's rock structures satisfy the elastic wave equation, but under the so-called acoustic approximation, this can be approximated by \eqref{eq:introwave}; see \cite[Section 1.2]{Ch:15} for a physical derivation of the elastic wave equation, and \cite[Section 1.2.6]{Ch:15} for a derivation and discussion of the acoustic approximation. Other physical scenarios involving waves modelled by either \eqref{eq:introwave} or Maxwell's equations are the propagation of sound in an inviscid fluid \cite[Section 2.1]{CoKr:13}, and Microwave imaging (see, e.g., \cite[Section 6.4]{BoDoGrSpTo:19}).

A mathematical and computational motivation for studying \eqref{eq:introhh} is that many of the difficulties one encounters when studying and numerically solving more complex wave-propagation models, such as the elastic wave equation, are also encountered with \eqref{eq:introhh}. Therefore \eqref{eq:introhh} is an appropriate starting point for mathematical study of, and numerical algorithms for, wave propagation models.

We now consider three characteristics of the above examples that will drive the theoretical and computational work in this thesis: high effective frequency, heterogeneity, and stochasticity.

The real-life examples above can have high effective frequency, that is, the wavenumber $k$ is large. The wavenumber may be large because the physical frequency is large (as in, for example non-destructive testing, where waves of frequency $1\times10^5$--$2\times10^7$ Hz (see, e.g., \cite{Bi}) are passed through materials to image their interior), or because the waves are low-frequency, but propagate over a large domain (as in seismic imaging, where the wave frequencies are in the range 1-100 Hz (see, e.g., \cite{Sc}) but the domain of interest is on the kilometre scale\optodo{Put in ref for Overthrust}\footnote{E.g., the SEG Overthrust model, a common benchmark for seismic imaging applications has domain size 20km $\times$ 20km $\times$ 4.65 km.}. These low-frequency, large-domain problems have many wavelengths in the domain, and hence, when they are scaled to a domain of size $\approx 1,$ they give rise to problems with large (effective) frequency.

Also, many of the examples above are modelled by the Helmholtz equation with \emph{heterogeneous} coefficients. For example, in subsurface imaging of the Earth's crust, waves will pass through the sea, different types of rock, and materials contained within these rocks, such as water or oil; each of these materials will have different properties, such as density and Lam\'e parameters, and therefore the coefficients $A$ and $n$ in \eqref{eq:introhh} will be heterogeneous (see, e.g. \cite[Section 1.2.4]{Ch:15} for an explanation of how the density and Lam\'e parameters manifest themselves in \eqref{eq:introwave}).

To understand the prescence of stochasticity in the above examples, we consider two possible problems associated with \eqref{eq:introhh}:
\ben
\item The \emph{forward problem}, where one knows the coefficients $A$ and $n$, and wishes to find solution $u$, and
\item The \emph{inverse problem}, where one knows the solution $u$ and wishes to find the coefficients $A$ and $n$.
  \een

The Helmholtz equation with \emph{random} coefficients arises when we model physical situations with uncertainty in the material parameters; this uncertainty can arise in both the forward and inverse problem. In the inverse problem, where one has sent an incident wave into an unknown medium, recorded the scattered wave, and reconstructs the medium, there will be uncertainties inherent in the process. For example, the scattered wave will only be recorded at discrete points in space, rather than everywhere, and these recordings will be subject to measurement error. These uncertanties in the measurement processes will result in uncertanties in the inferred properties of the medium. Alternatively, uncertainty arises in the forward problem, when we are already aware of uncertainty in our knowledge of the medium, and we wish to quanitfy the uncertainty in the wave passing through the uncertain medium. This occurs, for example, in radar imaging of ice sheets, where one wishes to know properties of the wave scattered by the ice, as in \cite{JiPi:18}.

This thesis will only focus on UQ for the forward problem. The forward problem and inverse problem share the common computational difficulty of needing to solve many (deterministic) realisations of \eqref{eq:introhh}. Whether the uncertainty in $A$ and $n$ has arisen as a result of the inverse or forward problem, most UQ algorithms will require many samples of the (random) solution of \eqref{eq:introhh}. As will be discussed below, obtaining one sample of the solution of \eqref{eq:introhh} is a considerable computational task, and so obtaining many (and `many' could easily mean thousands) of such samples is an even harder task. Reducing the computational cost of obtaining lots of samples of the solution of \eqref{eq:introhh} will be a main focus of the algorithms developed and studied in this thesis.\optodo{Put this somewhere better}

The computational techniques developed in this thesis are applicable to the inverse problem for \eqref{eq:introhh}. However, the inverse problem introduces other computational difficulties, unrelated to solving \eqref{eq:introhh}. Such difficulties are related to sampling the random coefficients $A$ and $n$; in wave propagation inverse problems the distributions of $A$ and $n$ may well be multi-modal\ednote{I've been able to construct a simple 1-D example of this---it'll go in an appendix, but it's not written up yet.}\optodo{Finish example in appendix} (the stochastic analogue of having multiple local minima), and constructing good samplers for such problems is an open research question\optodo{Find refs for this - ask Tom Pennington?}.

\subsection{Solving the Helmholtz Equation Numerically}\label{sec:numsolve}

We have just stated that it is hard to solve the (deterministic) Helmholtz equation
\beq\label{eq:introdet}
\grad \cdot (\Ad \grad \ud) + k^2 \,\nd\,\ud = -\fd,
\eeq
i.e., a single realisation of \eqref{eq:introhh}, numerically; we now provide some background on why this is the case. When solving \eqref{eq:introdet} numerically we discretise it to obtain a linear system
\beq\label{eq:intromat}
\Amat \bu = \bff.
\eeq
In this thesis we will be exclusively concerned with discretisation via finite elements, see \cref{chap:background} for the details of such a discretisation. The linear systems \eqref{eq:intromat} arising from standard finite-element discretisations of \eqref{eq:introdet} are hard to solve, as the matrices $\Amat$ are:
\ben
\item\label[itemblank]{it:nonh} non-Hermitian,
\item\label[itemblank]{it:indef} indefinite, and
  \item\label[itemblank]{it:large} large.
\een
    We will now briefly discuss each of these properties in turn, outlining why the matrices $\Amat$ have these three properties, and how these properties affetc the numerical solution of \eqref{eq:intromat}.

    For \cref{it:nonh}, the matrices $\Amat$ are non-Hermitian because the underlying boundary-value problems are not self-adjoint (see cite[Section 4.2]{Sp:15} for a discussion of the non-selfadjointness of exterior-boundary-value problems for the Helmholtz equation). This lack of slef-adjointness means the sesquilinear forms arising in standard variational formulations of \eqref{eq:introhh} are not conjugate symmetric, and this lack of conjugate symmetry is inherited by the discretisation matrices $\Amat$. the non-Hermitian nature of the matrices means that an iterative solver, such as GMRES, that is suitable for such matrices must be used.\ednote{Both---I'm struggling to find anything else to say here, is there anything I've missed? In particular, does the non-Hermitian nature of the matrices make the problem \emph{hard} to solve, or does it simply require we use an appropriate linear solver?}

    For \cref{it:indef}, the matrices $\Amat$ are indefinite because the sesquilinear forms arising from standard variational formulations of \eqref{eq:introhh} are not coercive. This indefiniteness means that GMRES applied to \eqref{eq:intromat} exhibits poor convergence properties, especially as the wavenumber $k$ is increased\ednote{Both---would it be helpful to run some experiments showing the blow-up in the number of GMRES iterations needed for convergence as $k$ increases?}\ednote{Both---I've been trying to find anything explaining why GMRES for indefinite systems doesn't behave well. Obviously one can't prove convergence if $\bzero \in W(\Amat)$, but is there any more intution about why it behaves poorly that I've missed?}. In addition, the standard convergence theory for GMRES (originally presented in \cite{El:82}\optodo{Find ref} and given in a helpful form in \cite[Equation (1.1)]{BeGoTy:06}) does not apply to indefinite systems, and so proving convergence results is also challenging.\ednote{Both---similar to the previous paragraph, I'm finding it hard to find anything else to say here, have I missed anything?}
    
For \cref{it:large}, the matrices $\Amat$ are large because the number of degrees of freedom must increase as $k$ increases. One can see this from interpolating the solution of \eqref{eq:introdet}; solutions $u$ of \eqref{eq:introdet} oscillate on a scale $1/k$, and therefore the number of degrees of freedom (interpolation points) must increase like $k^d$ (where $d$ is the spatial dimension) in order to keep the interpolation error for $u$ bounded. This need for increasing degrees of freedom with $k$ is illustrated in \cref{fig:introinterp}, where we see the interpolation error grows if the number of degrees of freedom is not increased with $k$. In practice one typically chooses to use 6--10 discretisation points in each dimension for each wavelength in the domain---this choice  empirically keeps the interpolation error at a reasonable size, but means the linear systems \eqref{eq:intromat} will have $k^d$ unknowns. 

\begin{figure}
\caption{\label{fig:introinterp} Figure showing interpolation error growing if mesh is not refined}
\end{figure}\optodo{Update Figure caption once figure is created}

However, discretising \eqref{eq:introdet} with a fixed number of points per wavelength is \emph{not} enough to keep the error in the finite-element solution of \eqref{eq:introdet} bounded as $k\rightarrow \infty.$ This is because standard-finite-element methods applied to the Helmholtz equation suffer from pollution, where the numerically calculated wave has a different wavelength to the true solution $u$, and so `drifts' away from $u$; moreover, this error increases as $k$ increases. See \cref{fig:intropoll} for an illustration of this phenomenon, and \cref{chap:background}\optodo{Better ref once chapter written} for an extended discussion of this phenomena.

\begin{figure}
\caption{\label{fig:intropoll} Figure showing pollution effect}
\end{figure}\optodo{Update Figure caption once figure is created}


In summary, numerically solving the Helmholtz equation gives rise to large (size at least $ \sim k^d$) linear systems, and the size of these linear systems increases as $k$ increases. The table \cref{tab:introlinsys} presents the sizes of the linear systems one obtains for different values of $k$, depending on the spatial dimension, and the properties of the finite-element solution that one requires.
\begin{table}
\begin{tabular}{c|cccccc}
 &\multicolumn{2}{c}{Interpolation error bounded}&\multicolumn{2}{c}{Finite-element error bounded}&\multicolumn{2}{c}{Quasi-optimality}\\
    &\multicolumn{2}{c}{($h = \pi/5 \times k^{-1}$)}&\multicolumn{2}{c}{($h = k^{-3/2}$)}&\multicolumn{2}{c}{($h = k^{-2}$)}\\
&2-D&3-D&2-D&3-D&2-D&3-D\\
\hline
$k$&&&&&&\\
$10$&$\approx 2.5\times 10^2$&$\approx 4 \times 10^3$&$10^3$&$\approx 3 \times 10^4$&$10^4$&$10^6$\\
$100$&$\approx 2.5\times 10^4$&$\approx 4 \times 10^6$&$10^6$&$10^9$&$10^8$&$10^{12}$\\
$1000$&$\approx 2.5\times 10^6$&$\approx 4 \times 10^9$&$10^9$&$\approx 3 \times 10^{13}$&$10^{12}$&$10^{18}$
\end{tabular}
\caption{\label{tab:introlinsys}Table showing the number of degrees of freedom that would be required to obtain various properties of finite-dimensional approximations of the solution $u$ of \eqref{eq:introdet}, for various values of $k$, in 2 and 3 spatial dimensions.}
\end{table}


We now turn our attention to how one might solve the large, indefinite, non-Hermitian linear systems \eqref{eq:intromat}. One option is to solve the linear systems \eqref{eq:intromat} using a direct solver\optodo{Look for direct solvers in books (e.g., Silvester, Greenbaum)} (solvers that, up to machine precision, invert the linear system \eqref{eq:intromat} exactly). Such solvers are incredibly competitive for solving \eqref{eq:introdet} in 2-D, if \eqref{eq:intromat} has up to $10^6$ unknowns; however, for larger linear systems \eqref{eq:intromat}, or those obtained from 3-D discretisations, direct solvers are not as competitive as so-called iterative solvers\ednote{Ivan---A good reference/introduction to this kind of stuff?}. An iterative solver is one that does not solve \eqref{eq:intromat} exactly, but rather produces a sequence of approximations to the solution of \eqref{eq:intromat}. A standard iterative solver to use for non-Hermitian linear systems is GMRES; this is the solver we will use throughout this thesis. However, numerical evidence shows that GMRES applied to \eqref{eq:intromat} can perform very badly (the number of interations to acheive convergence can grow dramatically with $k$, and moreover, it is hard to prove convergence results for GMRES applied to \eqref{eq:intromat} as the matrices $\Amat$ are typically indefinite\optodo{Understand why this is the case}. An explanation of how the wave-nature of the solution of the Helmholtz equation causes slow convergence of iterative methods for \eqref{eq:intromat} is explained in \cite[Section 2.1]{ErGa:12}, using a finite-difference approximation of the Helmholtz equation as an example.\optodo{Find an example of behaviour of non-preconditioned GMRES deteriorating as $k\rightarrow \infty.$}\optodo{Find ref for error going south as $k$increases}.

As GMRES applied to \eqref{eq:intromat} performs badly, we consider preconditioning \eqref{eq:intromat}, that is, solving the equivalent linear system
\beq\label{eq:intropre}
\PmatI\Amat \bu = \PmatI \bff
\eeq
for some matrix $\Pmat$. The goal of preconditioning\footnote{We have only considered left-preconditioning, that is, multiplying $\Amat$ from the left by $\PmatI$. However, one can also-consider right-preconditioning, that is, solving the linear system $\Amat \PmatI \butilde = \bff,$ the solution $\bu$ is then given by $\bu = \PmatI \butilde.$} is to choose the preconditioner $\Pmat$ such that:
\ben
\item\label[listrequirement]{it:intropreone} The equation \eqref{eq:intropre} is easy to solve iteratively, and
\item\label[listrequirement]{it:intropretwo} The action of $\PmatI$ is cheap to compute.
\een
The ideal preconditioner from the point of view of \cref{it:intropreone} is $\Pmat = \AmatI$, however, in view of \cref{it:intropretwo}, if we could cheaply compute the action of $\AmatI,$ we could cheaply solve \eqref{eq:intromat}, and there would be no need for preconditioning. Hence, one needs to balance the \cref{it:intropreone,it:intropretwo} so that one obtains a good approximation of $\AmatI$ that is cheap to apply. There are several groups around the world working on the construction of good preconditioners for the Helmholtz equation, and this is an open research area. The design of such preconditioners is not the focus of this thesis\optodo{Either summarise preconditioners here, somewhere else, or put a link to some overviews - Gander SIREV?}.

\paragraph{Issues from UQ} On top of all the above issues in solving the deterministic Helmholtz equation \eqref{eq:introdet}, when seeking to perform UQ calculations for the stochastic Helmholtz equation \eqref{eq:introhh} one often needs to solve many realisations of \eqref{eq:introhh}.  For example, if one wants to calculate $\EXP{Q(u)},$ where $Q$ is some quantity of interest, then one can use the sample average of many realisations of $u;$
\beqs
\EXP{Q(u)} = \int_{\Omega} Q(u(\omega)) \ddPPomega \approx \frac1N \sum_{j=1}^N Q(u(\omega^{(j)})).
\eeqs
Observe that to compute the sample average, one needs to solve many (which we emphasise again, could easily be thousands) different deterministic Helmholtz problems which, as has just been discussed, are each individually difficult to solve. This situation arises when using sampling-based methods such as Monte-Carlo or Stochastic-Collocation methods to compute properties of the solution $u$ of \eqref{eq:introhh}, or approximations to $u$ itself. Rigorously studying \eqref{eq:introhh}, devising computational techniques to reduce the cost of such UQ calculations, and rigorously justifying this reduction, is the subject of this thesis.\optodo{Put more in here?}

%% The aims of this thesis are to conduct a detailed study of the Helmholtz equation in random media, with special regard to high-frequency behaviour, and to provide fast, rigorously justifiable UQ methods for the high-frequency Helmholtz equation. 

%% We then seek to design numerical methods for the high-frequency Helmholtz equation that provide speedup over n\"aive numerical methods, in order to make UQ calculations for the Helmholtz equation more feasible. We also wish to analyse these numerical methods and show how their behaviour (both speedup and computational cost) depend on the wavenumber $k$. We propose two complementary numerical methods to speed up UQ calculations for the Helmholtz equation.






\section{The Main Acheivements of the Thesis}

The main acheivements of the thesis are as follows:


\ben

  \item\label[itemachievement]{it:achievements-error} New bounds on the error for the finite-element method applied to the (deterministic) Helmholtz equation in heterogeneous media; these bounds are explicit in their dependence on the wavenumber $k$, and on the coefficients $A$ and $n$\optodo{Not really $A$....}
\een

These error bounds are the first for the Helmholtz equation in a heterogeneous medium; similar bounds have been proved for the Helmholtz equation in a homogeneous medium in, e.g., \cite{Wu:14,DuWu:15,ChNi:18} and for a homogeneous medium with a small, frquency-dependent nonlinear perturbation in \cite{WuZo:18}. These bounds (and their explicit dependence on $k$, $A4$ and $n$) are crucial for the analysis of the numerical methods developed in this thesis.

\setlist[enumerate]{resume}

\ben

\item\label[itemachievement]{it:achievements-bounds} Well-posedness results and a priori bounds on the solution of the Helmholtz equation in random media, where the results and bounds obtained are frequency-independent.  The arguments behind these results are written in a sufficiently general way that they can be used, in principle, to conclude similar results for a range of stochastic elliptic PDEs. 

  \een

This work is an advance on the only previous work in the literature, \cite{FeLiLo:15}, in which similar results and bounds were proved, but under restrictions that became more stringent as the frequency increased; in contrast the results in this thesis are frequency-independent. To prove such frequency-independent results, we will consider classes of random media that are almost-surely nontrapping. This nontrapping assumption will allow us to obtain our frequency-independent results. These results on well-posedness and a priori bounds are crucial for analysing the numerical methods that follow. Our results show that the problems we are solving are well-posed, and will enable us to rigorously prove properties of the numerical methods considered in this thesis. We expect that the arguments behind these results can be used in other cases where the bilinear form given by the PDE is indefinite, such as for the time-harmonic Maxwell's equations.

  \setlist[enumerate]{resume}
  \ben
\item\label[itemachievement]{it:achievements-nbpc} A computational strategy (nearby preconditioning) that reduces the computational cost of solving many realisations of the Helmholtz equation in random media. 
\item\label[itemachievement]{it:achievements-nbpcnum} Numerical experiments that show the rigorous analysis of nearby preconditioning may not be\optodo{change?} not sharp, and that the method is, in practice, more effective than can be rigorously proved. We demonstrate the effectiveness of nearby preconditioning when applied to a Quasi-Monte-Carlo method for the Helmholtz equation.
  \een

  %The reduction in computational cost is gained by reusing the preconditioner from one realisation of the Helmholtz equation for subsequent `nearby' realisations. This computational method is rigorously analysed, and its effectiveness is precisely characterised, although this effectiveness does degrade as the frequency of the problems is increased. However, the effectiveness does still degrade as frequency is increased.
  
  The nearby preconditioning strategy seeks to reduce the computational cost of assembling preconditioners for many deterministic Helmholtz problems. This reduction is achieved by re-using a preconditioner from one deterministic Helmholtz problem for other, nearby Helmholtz problems. As far as we are aware, this is the first time such a strategy has been rigorously studied for the Helmholtz equation. We prove that if the coefficients of the underlying PDEs are sufficiently close (or `nearby'), then GMRES applied to $\AmatoI\Amatt$ (where $\Amato$ and $\Amatt$ arise from the discretisation of different Helmholtz problems) will converge in a number of iterations that is independent of $k.$ However, the conditions for 'sufficient closeness' that we prove depend on either $k$ or the mesh size $h$. The numerical experiments show the sharpness (in some cases) or the lack of sharpness (in other cases) of our proven results.

 % In \cref{chap:nbpc} we propose a computational technique, \emph{nearby preconditioning}, that speeds up the process of solving many realisations of the Helmholtz equation by reusing preconditioners from one realisation for (potentially) many subsequent `nearby' realisations. In this theoretical study, we assume that we have access to the action of an exact preconditioner for one Helmholtz problem, and study the convergence of GMRES for subsequent problems. That is, we investigate the convergence of GMRES applied to $\AmatoI\Amatt$, where $\Amato$ and $\Amatt$ are matrices arising from finite-element discretisations of the Helmholtz equation. We show that if the coefficients of the underlying PDEs are sufficiently close (or `nearby'), then GMRES applied to $\AmatoI\Amatt$ will converge in a number of iterations that is independent of $k.$ However, the conditions for 'sufficient closeness' that we prove depend on either $k$ or the mesh size $h$. We then provide numerical experiments showing the sharpness (in some cases) or the lack of sharpness (in other cases) of our proven results.

  

%    \setlist[enumerate]{resume}
  \ben



\item\label[itemachievement]{it:achievements-mlmc} Theoretical analysis of the Monte-Carlo (MC) and Multi-Level Monte Carlo (MLMC) methods applied to the Helmholtz equation in random media.


\item\label[itemachievement]{it:achievements-mlmcnum} Computational experiments for MLMC that show that, in many cases, the speedup one obtains using MLMC is greater than that predicting theoretically\ednote{I've no idea what the result of these computations will be at this point!}.

    \item\label[itemachievement]{it:achievements-qmc} Computational investigation into Quasi-Monte-Carlo (QMC) methods applied to the Helmholtz equation in random media. 
  \een

  MLMC is a variance reduction technique that uses computations on a sequence of meshes to reduce the variance in UQ calculations, and therefore to reduce the number of realisations of the Helmholtz equation that need to be solved. We extend the existing abstract MLMC analysis in the literature to the case where the finite-element error is dependent on an additional parameter (here this parameter is the wavenumber $k$), and then apply this abstract analysis to the Helmholtz equation, showing that we obtain speedup over MC, with the relative speedup being independent of $k.$ We then verify this speedup computationally, and also perform computations giving insight into the behaviour of QMC methods for the Helmholtz equation; these results are the first available in the literature.

  
  %. We also show that the error in MC is independent of the wavenumber $k$, and we show that MLMC gives a cost reduction over MC, with the relative cost reduction being independent of $k.$
  
%The second strategy, somewhat orthogonal to the first, is to use a Multi-Level Monte Carlo (MLMC) method to reduce the number of samples needed when performing UQ calculations. By reducing the number of samples needed, we will decrease the computational cost for UQ calculations. The analysis of this method requires an extension of standard MLMC theory to the case where the numerical error is dependent on a parameter besides the mesh size (in our case, the error in finite-element calculations depends on the wavenumber $k$). We will see that a MLMC approach does reduce cost, both in theory and in practice, and that the relative cost reduction with respect to a standard Monte Carlo method does not degrade as $k$ grows.

%we study the multi-level Monte Carlo (MLMC) method for reducing the variance in UQ calculations for the Helmholtz equation in random media. We first extend the abstract theory for MLMC to the sitation when there is an additional parameter (in our case, the wavenumber $k$), alongside the mesh size $h$, governing the size of the error in numerical approximations. Having extended the abstract theory, we then apply it to the Helmholtz equation for a variety of different quantities of interest, and we prove that MLMC gives a cost reduction over the Monte-Carlo method, and that this reduction is independent of $k$. We then investigate MLMC numerically, and find that in many cases the speedup we observe in numerics is better than the speedup we can prove rigorously.

\section{The Structure of the thesis}

In \cref{chap:background} we give background material on the (deterministic) Helmholtz equation and its discretisation via finite elements; this material will be necessary to understand the rest of this thesis. We then present recent results in \cite{GrPeSp:19} concerning the well-posedness of the deterministic heterogeneous Helmholtz equation and a priori bounds on its solution of which the author of this thesis was a co-author. These results are used in some of the developments in this thesis, especially in \cref{chap:stochastic}. We also give an overview of the theory of finite-element discretiations of the Helmholtz equation, and prove the results in \cref{it:achievements-error}.

In \cref{chap:stochastic} we prove the results in \cref{it:achievements-bounds} for three formulations of the stochastic exterior Dirichlet problem (SEDP) for the Helmholtz equation in random media. These results are underpinned by the well-posedness results and a priori bounds obtained in \cite{GrPeSp:19} for the heterogeneous (but non-random) Helmholtz equation.

In \cref{chap:nbpc} we develop the nearby preconditioning strategy described in \cref{it:achievements-nbpc}, prove the results on its effectiveness, and perform the numerical investigation of its effectiveness as in \cref{it:achievements-nbpcnum}. We finally apply nearby preconditioning to a QMC method for the Helmholtz equation, obtaining speedup.

In \cref{chap:mlmc} we develop abstract MLMC theory as in \cref{it:achievements-mlmc}, and then apply this to the Helmholtz equation. We then numerically investigate the effectiveness of MLMC as in \cref{it:achievements-mlmcnum}, seeing speedup outside of that predicted by the theory. We finally provide preliminary numerical investigation into QMC methods for the Helmholtz equation, as in \cref{it:achievements-qmc}.

%for MLMC later?:
%(that is the ratio $\CMC(\eps)/\CMLMC(\eps)$, where $\CMC(\eps)$ is the cost for the root-mean-sqaured
